/*
 * Apache License
 * Version 2.0, January 2004
 * http://www.apache.org/licenses/
 *
 * TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 *
 * 1. Definitions.
 *
 * "License" shall mean the terms and conditions for use, reproduction, and
 * distribution as defined by Sections 1 through 9 of this document.
 *
 * "Licensor" shall mean the copyright owner or entity authorized by the copyright
 * owner that is granting the License.
 *
 * "Legal Entity" shall mean the union of the acting entity and all other entities
 * that control, are controlled by, or are under common control with that entity.
 * For the purposes of this definition, "control" means (i) the power, direct or
 * indirect, to cause the direction or management of such entity, whether by
 * contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the
 * outstanding shares, or (iii) beneficial ownership of such entity.
 *
 * "You" (or "Your") shall mean an individual or Legal Entity exercising
 * permissions granted by this License.
 *
 * "Source" form shall mean the preferred form for making modifications, including
 * but not limited to software source code, documentation source, and configuration
 * files.
 *
 * "Object" form shall mean any form resulting from mechanical transformation or
 * translation of a Source form, including but not limited to compiled object code,
 * generated documentation, and conversions to other media types.
 *
 * "Work" shall mean the work of authorship, whether in Source or Object form, made
 * available under the License, as indicated by a copyright notice that is included
 * in or attached to the work (an example is provided in the Appendix below).
 *
 * "Derivative Works" shall mean any work, whether in Source or Object form, that
 * is based on (or derived from) the Work and for which the editorial revisions,
 * annotations, elaborations, or other modifications represent, as a whole, an
 * original work of authorship. For the purposes of this License, Derivative Works
 * shall not include works that remain separable from, or merely link (or bind by
 * name) to the interfaces of, the Work and Derivative Works thereof.
 *
 * "Contribution" shall mean any work of authorship, including the original version
 * of the Work and any modifications or additions to that Work or Derivative Works
 * thereof, that is intentionally submitted to Licensor for inclusion in the Work
 * by the copyright owner or by an individual or Legal Entity authorized to submit
 * on behalf of the copyright owner. For the purposes of this definition,
 * "submitted" means any form of electronic, verbal, or written communication sent
 * to the Licensor or its representatives, including but not limited to
 * communication on electronic mailing lists, source code control systems, and
 * issue tracking systems that are managed by, or on behalf of, the Licensor for
 * the purpose of discussing and improving the Work, but excluding communication
 * that is conspicuously marked or otherwise designated in writing by the copyright
 * owner as "Not a Contribution."
 *
 * "Contributor" shall mean Licensor and any individual or Legal Entity on behalf
 * of whom a Contribution has been received by Licensor and subsequently
 * incorporated within the Work.
 *
 * 2. Grant of Copyright License.
 *
 * Subject to the terms and conditions of this License, each Contributor hereby
 * grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free,
 * irrevocable copyright license to reproduce, prepare Derivative Works of,
 * publicly display, publicly perform, sublicense, and distribute the Work and such
 * Derivative Works in Source or Object form.
 *
 * 3. Grant of Patent License.
 *
 * Subject to the terms and conditions of this License, each Contributor hereby
 * grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free,
 * irrevocable (except as stated in this section) patent license to make, have
 * made, use, offer to sell, sell, import, and otherwise transfer the Work, where
 * such license applies only to those patent claims licensable by such Contributor
 * that are necessarily infringed by their Contribution(s) alone or by combination
 * of their Contribution(s) with the Work to which such Contribution(s) was
 * submitted. If You institute patent litigation against any entity (including a
 * cross-claim or counterclaim in a lawsuit) alleging that the Work or a
 * Contribution incorporated within the Work constitutes direct or contributory
 * patent infringement, then any patent licenses granted to You under this License
 * for that Work shall terminate as of the date such litigation is filed.
 *
 * 4. Redistribution.
 *
 * You may reproduce and distribute copies of the Work or Derivative Works thereof
 * in any medium, with or without modifications, and in Source or Object form,
 * provided that You meet the following conditions:
 *
 * You must give any other recipients of the Work or Derivative Works a copy of
 * this License; and
 * You must cause any modified files to carry prominent notices stating that You
 * changed the files; and
 * You must retain, in the Source form of any Derivative Works that You distribute,
 * all copyright, patent, trademark, and attribution notices from the Source form
 * of the Work, excluding those notices that do not pertain to any part of the
 * Derivative Works; and
 * If the Work includes a "NOTICE" text file as part of its distribution, then any
 * Derivative Works that You distribute must include a readable copy of the
 * attribution notices contained within such NOTICE file, excluding those notices
 * that do not pertain to any part of the Derivative Works, in at least one of the
 * following places: within a NOTICE text file distributed as part of the
 * Derivative Works; within the Source form or documentation, if provided along
 * with the Derivative Works; or, within a display generated by the Derivative
 * Works, if and wherever such third-party notices normally appear. The contents of
 * the NOTICE file are for informational purposes only and do not modify the
 * License. You may add Your own attribution notices within Derivative Works that
 * You distribute, alongside or as an addendum to the NOTICE text from the Work,
 * provided that such additional attribution notices cannot be construed as
 * modifying the License.
 * You may add Your own copyright statement to Your modifications and may provide
 * additional or different license terms and conditions for use, reproduction, or
 * distribution of Your modifications, or for any such Derivative Works as a whole,
 * provided Your use, reproduction, and distribution of the Work otherwise complies
 * with the conditions stated in this License.
 *
 * 5. Submission of Contributions.
 *
 * Unless You explicitly state otherwise, any Contribution intentionally submitted
 * for inclusion in the Work by You to the Licensor shall be under the terms and
 * conditions of this License, without any additional terms or conditions.
 * Notwithstanding the above, nothing herein shall supersede or modify the terms of
 * any separate license agreement you may have executed with Licensor regarding
 * such Contributions.
 *
 * 6. Trademarks.
 *
 * This License does not grant permission to use the trade names, trademarks,
 * service marks, or product names of the Licensor, except as required for
 * reasonable and customary use in describing the origin of the Work and
 * reproducing the content of the NOTICE file.
 *
 * 7. Disclaimer of Warranty.
 *
 * Unless required by applicable law or agreed to in writing, Licensor provides the
 * Work (and each Contributor provides its Contributions) on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied,
 * including, without limitation, any warranties or conditions of TITLE,
 * NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are
 * solely responsible for determining the appropriateness of using or
 * redistributing the Work and assume any risks associated with Your exercise of
 * permissions under this License.
 *
 * 8. Limitation of Liability.
 *
 * In no event and under no legal theory, whether in tort (including negligence),
 * contract, or otherwise, unless required by applicable law (such as deliberate
 * and grossly negligent acts) or agreed to in writing, shall any Contributor be
 * liable to You for damages, including any direct, indirect, special, incidental,
 * or consequential damages of any character arising as a result of this License or
 * out of the use or inability to use the Work (including but not limited to
 * damages for loss of goodwill, work stoppage, computer failure or malfunction, or
 * any and all other commercial damages or losses), even if such Contributor has
 * been advised of the possibility of such damages.
 *
 * 9. Accepting Warranty or Additional Liability.
 *
 * While redistributing the Work or Derivative Works thereof, You may choose to
 * offer, and charge a fee for, acceptance of support, warranty, indemnity, or
 * other liability obligations and/or rights consistent with this License. However,
 * in accepting such obligations, You may act only on Your own behalf and on Your
 * sole responsibility, not on behalf of any other Contributor, and only if You
 * agree to indemnify, defend, and hold each Contributor harmless for any liability
 * incurred by, or claims asserted against, such Contributor by reason of your
 * accepting any such warranty or additional liability.
 *
 * END OF TERMS AND CONDITIONS
 *
 * APPENDIX: How to apply the Apache License to your work
 *
 * To apply the Apache License to your work, attach the following boilerplate
 * notice, with the fields enclosed by brackets "[]" replaced with your own
 * identifying information. (Don't include the brackets!) The text should be
 * enclosed in the appropriate comment syntax for the file format. We also
 * recommend that a file or class name and description of purpose be included on
 * the same "printed page" as the copyright notice for easier identification within
 * third-party archives.
 *
 *    Copyright 2013 Aurelian Tutuianu
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package rapaio.tutorial.pages;

import rapaio.data.*;
import rapaio.datasets.Datasets;
import rapaio.explore.Summary;

import static rapaio.explore.Workspace.*;

import rapaio.filters.ColFilters;
import rapaio.graphics.Plot;
import rapaio.graphics.plot.Lines;
import rapaio.graphics.plot.Points;
import rapaio.sample.StatSampling;
import rapaio.supervised.Classifier;
import rapaio.supervised.tree.RandomForest;

import java.io.IOException;
import java.net.URISyntaxException;
import java.util.List;

/**
 * User: <a href="mailto:padreati@yahoo.com">Aurelian Tutuianu</a>
 */
public class ClassificationWithRF implements TutorialPage {
    @Override
    public String getPageName() {
        return "ClassificationWithRandomForest";
    }

    @Override
    public String getPageTitle() {
        return "Classification with Random Forests";
    }

    @Override
    public void render() throws IOException, URISyntaxException {
        heading(1, "Classification with Random Forests");

        p("Random forests are an ensemble learning method for " +
                "classification (and regression) that operate by constructing " +
                "a multitude of decision trees at training time and outputting " +
                "the class that is the mode of the classes output by individual " +
                "trees.");
        p("The algorithm for inducing a random forest was developed " +
                "by Leo Breiman and Adele Cutler, and \"Random Forests\" is their trademark. " +
                "More about this topic can be found at " +
                "<a href=\"http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\">" +
                "http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm</a>");

        heading(3, "Implementation");

        p("Rapaio toolbox is and will continue to be under construction for a long " +
                "period. However, there is a Random Forest implementation available and " +
                "ready to be used. Implemented features:");
        p("1. Classification only (regression will follow soon).");
        p("2. It uses Gini impurity function for finding the best split attributes/values, " +
                "according with the original specifications. " +
                "It can be implemented also with InfoGain (as it is implemented in Weka), or" +
                "something else. However there is not a huge difference in results, thus " +
                "for now remains according with the original specifications.");
        p("3. It computes OOB (Out of bag) error, which is an estimation constructed " +
                "in the same way as a cross validation. For faster " +
                "execution one can disable oob computation.");
        p("4. Does not perform yet any of the two ways of feature importance, " +
                "it will be implemented soon.");
        p("5. There is no computation of proximity and I do not know for sure if I want " +
                "that in the immediate future.");

        heading(3, "Why Random Forests?");

        p("Random Forests are very popular due to the fact that the intuition behind " +
                "the algorithm is easy to understand, and, to some extent, " +
                "easy to implement. However, I found a very popular opinion that " +
                "Random Forests is something like a panacea for learning. In my humble " +
                "opinion it is far from that, simply because there is no such " +
                "thing in machine learning. ");

        p("Random Forests learns well in a variety of situations and is usually " +
                "useful when it is very hard or complex to understand the mechanics " +
                "of your data. However finding and exploiting valuable knowledge " +
                "from data is often more successful than random forests.");

        p("I like random forests for some other qualities which I found more " +
                "valuable, but not so popular:");
        p("- ability to capture knowledge about importance of the features");
        p("- possibility to be used as an exploratory tool or for " +
                "unsupervised learning");
        p("- the theory behind the algorithm which explains how some variance " +
                "vanishes, how some \"noisy random salt\" produces stability; " +
                "all the inspiring simple or subtle things from the theory behind it");

        heading(3, "Data setup");

        p("I will use a classical data set called spam-base, data set which was imported " +
                "into Rapaio toolbox from the well-known UCI repository: " +
                "<a href=\"http://archive.ics.uci.edu/ml/datasets/Spambase\">" +
                "http://archive.ics.uci.edu/ml/datasets/Spambase</a> ");

        p("In order to compute faster I will use only some dimensions of this dataset. " +
                "I will use for prediction only the first 20 features and the class called \"spam\"");

        code("        Frame all = Datasets.loadSpamBase();\n" +
                "        all = ColFilters.retainCols(all, \"1-20,spam\");\n" +
                "\n" +
                "        Summary.summary(ColFilters.retainCols(all, \"1-5\"));\n" +
                "        Summary.summary(ColFilters.retainCols(all, \"spam\"));\n");

        Frame all = Datasets.loadSpamBase();
        all = ColFilters.retainCols(all, "1-20,spam"); // keep only some columns

        Summary.summary(ColFilters.retainCols(all, "1-5")); // summary of first 5 columsn
        Summary.summary(ColFilters.retainCols(all, "spam"));

        p("Above you see some 5-number information on the data. It is not exhaustive " +
                "since it is not the purpose of this tutorial.");

        p("We will split the data set in two parts, one will be used for " +
                "training the random forest and another one will be used " +
                "for testing its prediction accuracy. ");

        code("        List<Frame> frames = StatSampling.randomSample(all, new int[]{all.getRowCount() * 15 / 100});\n" +
                "        Frame train = frames.get(0);\n" +
                "        Frame test = frames.get(1);\n");
        List<Frame> frames = StatSampling.randomSample(all, new int[]{all.getRowCount() * 15 / 100});
        Frame train = frames.get(0);
        Frame test = frames.get(1);

        heading(3, "Playing with number of trees grown");

        p("Now that we have a train and a test data set we can learn and predict. " +
                "RF grows a number of trees over bootstrap samples and use " +
                "voting for classification. How large this number of trees must be? " +
                "You can check how well you predict as the number of trees grows. ");


        int pos = 0;
        final Vector index = new IndexVector("number of trees", 400);
        final Vector accuracy = new NumericVector("test error", 400);
        final Vector oob = new NumericVector("oob error", 400);
        for (int mtree = 1; mtree < 200; mtree += 10) {
            RandomForest rf = new RandomForest(mtree, 2, true);
            rf.learn(train, "spam");
            rf.predict(test);
            index.setIndex(pos, mtree);
            accuracy.setValue(pos, 1 - computeAccuracy(rf, test));
            oob.setValue(pos, rf.getOobError());
            pos++;
        }

        draw(new Plot() {{
            new Lines(this, index, accuracy) {{
                opt().setColorIndex(new OneIndexVector(2));
            }};
            new Points(this, index, accuracy) {{
                opt().setColorIndex(new OneIndexVector(2));
            }};
            new Lines(this, index, oob);
            new Points(this, index, oob);

            setLeftLabel("test (blue), oob (black)");
            setTitle("Accuracy errors (% misclassified)");
            opt().setYRange(0, 0.4);
        }}, 600, 400);

        p("Note from the previous plot how both test and oob errors " +
                "goes down as the number of trained trees grown. " +
                "However, the improvement stops at some point and " +
                "become useless to add new trees.");

        code("        int pos = 0;\n" +
                "        Vector index = new IndexVector(\"number of trees\", 1000);\n" +
                "        Vector accuracy = new NumericVector(\"test error\", 1000);\n" +
                "        Vector oob = new NumericVector(\"oob error\", 1000);\n" +
                "        for (int mtree = 1; mtree < 100; mtree += 5) {\n" +
                "            RandomForest rf = new RandomForest(mtree, 3, true);\n" +
                "            rf.learn(train, \"spam\");\n" +
                "            ClassifierModel model = rf.predict(test);\n" +
                "            index.setIndex(pos, mtree);\n" +
                "            accuracy.setValue(pos, 1 - computeAccuracy(model, test));\n" +
                "            oob.setValue(pos, rf.getOobError());\n" +
                "            pos++;\n" +
                "        }\n" +
                "        Plot p = new Plot();\n" +
                "        Lines lines = new Lines(p, index, accuracy);\n" +
                "        lines.opt().setColorIndex(new OneIndexVector(2));\n" +
                "        p.add(lines);\n" +
                "        Points pts = new Points(p, index, accuracy);\n" +
                "        pts.opt().setColorIndex(new OneIndexVector(2));\n" +
                "        p.add(pts);\n" +
                "        p.add(new Lines(p, index, oob));\n" +
                "        p.add(new Points(p, index, oob));\n" +
                "\n" +
                "        p.setLeftLabel(\"test (blue), oob (black)\");\n" +
                "        p.setTitle(\"Accuracy errors (% misclassified)\");\n" +
                "        p.opt().setYRange(0, 0.4);\n" +
                "        draw(p, 600, 400);\n");

        heading(3, "Playing with number of random features");

        p("The main difference between bagging and random forests is " +
                "that while bagging relies only grows trees on bootstraps, " +
                "the random forests introduces randomization in order " +
                "to uncorrelate those trees. The main effect of this " +
                "is that it will further reduce the variance of the " +
                "prediction and the compensation is better accuracy.");

        pos = 0;
        final Vector index1 = new IndexVector("mtree", 1000);
        final Vector accuracy1 = new NumericVector("test error", 1000);
        final Vector oob1 = new NumericVector("oob error", 1000);
        for (int mcol = 1; mcol < 20; mcol += 1) {

            RandomForest rf = new RandomForest(30, mcol, true);
            rf.learn(train, "spam");
            rf.predict(test);
            index.setIndex(pos, mcol);
            accuracy.setValue(pos, 1 - computeAccuracy(rf, test));
            oob.setValue(pos, rf.getOobError());

            pos++;
        }
        draw(new Plot() {{
            new Lines(this, index1, accuracy1) {{
                opt().setColorIndex(2);
            }};
            new Points(this, index1, accuracy1){{
                opt().setColorIndex(2);
            }};
            new Lines(this, index1, oob1);
            new Points(this, index1, oob1);
            setLeftLabel("test (blue), oob (black");
            setBottomLabel("mcols - number of features considered");
            setTitle("Accuracy errors (% misclassified)");
            opt().setYRange(0, 0.4);
        }}, 600, 400);

        p("It can be seen here that the best prediction according " +
                "with oob and the test used is when the number of " +
                "random features lies in 3 to 6 interval.");

        p("And the code which produced the last plot is listed below.");
        code("        pos = 0;\n" +
                "        index = new IndexVector(\"mtree\", 1000);\n" +
                "        accuracy = new NumericVector(\"test error\", 1000);\n" +
                "        oob = new NumericVector(\"oob error\", 1000);\n" +
                "        for (int mtree = 1; mtree < 20; mtree += 1) {\n" +
                "\n" +
                "            RandomForest rf = new RandomForest(10, mtree, true);\n" +
                "            rf.learn(train, \"spam\");\n" +
                "            ClassifierModel model = rf.predict(test);\n" +
                "\n" +
                "            index.setIndex(pos, mtree);\n" +
                "            accuracy.setValue(pos, 1 - computeAccuracy(model, test));\n" +
                "            oob.setValue(pos, rf.getOobError());\n" +
                "\n" +
                "            pos++;\n" +
                "        }\n" +
                "        p = new Plot();\n" +
                "        lines = new Lines(p, index, accuracy);\n" +
                "        lines.opt().setColorIndex(new OneIndexVector(2));\n" +
                "        p.add(lines);\n" +
                "        pts = new Points(p, index, accuracy);\n" +
                "        pts.opt().setColorIndex(new OneIndexVector(2));\n" +
                "        p.add(pts);\n" +
                "        p.add(new Lines(p, index, oob));\n" +
                "        p.add(new Points(p, index, oob));\n" +
                "        p.setLeftLabel(\"test (blue), oob (black\");\n" +
                "        p.setBottomLabel(\"mcols - number of features considered\");\n" +
                "        p.setTitle(\"Accuracy errors (% misclassified)\");\n" +
                "        p.opt().setYRange(0, 0.4);\n" +
                "        draw(p, 600, 400);\n");

        p("Note: the sole purpose of this tutorial is to show what and how it can " +
                "be done with Rapaio toolbox library. ");

        p(">>>This tutorial is generated with Rapaio document printer facilities.<<<");
    }

    private double computeAccuracy(Classifier model, Frame test) {
        Vector predict = model.getPrediction();
        double accuracy = 0;
        double total = predict.getRowCount();
        for (int i = 0; i < predict.getRowCount(); i++) {
            if (test.getCol("spam").getIndex(i) == predict.getIndex(i)) {
                accuracy += 1.;
            }
        }
        return accuracy / total;
    }
}
